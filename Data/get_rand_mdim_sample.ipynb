{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "cont_sample_multidim = []\n",
    "sample_points = np.random.randint(150000, len(data) + 1, 1000)\n",
    "\n",
    "for point in sample_points:\n",
    "    new_point_X = []\n",
    "    temp = pd.DataFrame(data.iloc[point])\n",
    "    new_point_y = temp.loc['time_to_failure'].to_list()[0]\n",
    "    \n",
    "    for i in range(150000):\n",
    "        temp = pd.DataFrame(data.iloc[point - i])\n",
    "        temp = temp.loc['acoustic_data'].to_list()[0]\n",
    "        new_point_X.append(temp)\n",
    "    \n",
    "    cont_sample_multidim.append([new_point_X, new_point_y])\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(cont_sample_multidim)):\n",
    "    X.append(cont_sample_multidim[i][0])\n",
    "    y.append(cont_sample_multidim[i][1])\n",
    "\n",
    "pd.DataFrame(X).to_csv(\"rand_mdim_sample_100_X\", index=False)\n",
    "pd.DataFrame(y).to_csv(\"rand_mdim_sample_100_y\", index=False)\n",
    "\n",
    "best_score = np.infty\n",
    "\n",
    "print(\"Done sampling\")\n",
    "print(\"\\nStart KNN\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    score = root_mean_squared_error(y_pred_test, y_test)\n",
    "    results.append([k, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart LR\")\n",
    "results = []\n",
    "\n",
    "for i in range(5):#10):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_test = lr.predict(X_test)\n",
    "    score = root_mean_squared_error(y_pred_test, y_test)\n",
    "    results.append([i, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart SVR\")\n",
    "results = []\n",
    "\n",
    "for e in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1]:#10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 1000]:\n",
    "        regr = make_pipeline(StandardScaler(), SVR(C=c, epsilon=e))\n",
    "        regr.fit(X, y)\n",
    "        y_pred_test = regr.predict(X_test)\n",
    "        score = root_mean_squared_error(y_pred_test, y_test)\n",
    "        results.append([e, c, score])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"best score: \", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStart SVR\")\n",
    "best_score = 0\n",
    "results = []\n",
    "\n",
    "for e in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1]:\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 1000]:\n",
    "        regr = make_pipeline(StandardScaler(), SVR(C=c, epsilon=e))\n",
    "        regr.fit(X, y)\n",
    "        y_pred_test = regr.predict(X_test)\n",
    "        score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "        results.append([e, c, score])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"best score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"rand_mdim_sample_100_X\", index_col=False)\n",
    "y = pd.read_csv(\"rand_mdim_sample_100_y\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Start Program\")\n",
    "X_150kdim = []\n",
    "X_sum = []\n",
    "X_avg = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X_sum.append([sum( X.iloc[i].to_list() ), X.iloc[i].to_list()[150000-1]])\n",
    "    X_avg.append([ (X_sum[i][0]/len( X.iloc[1].to_list() ) ), X.iloc[i].to_list()[150000-1]] )\n",
    "    X_150kdim.append(X.iloc[i].to_list())\n",
    "\n",
    "#pd.DataFrame(X_sum).to_csv(\"rand_mdim_sample_100_X_sum\", index=False)\n",
    "#pd.DataFrame(X_avg).to_csv(\"rand_mdim_sample_100_X_avg\", index=False)\n",
    "\n",
    "print(\"Done making arrays\")\n",
    "\n",
    "best_score = np.infty\n",
    "\n",
    "print(\"\\nStart KNN\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sum, y, test_size=0.20, random_state=0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([k, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart LR\")\n",
    "results = []\n",
    "\n",
    "for i in range(5):#10):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_test = lr.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([i, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart SVR\")\n",
    "results = []\n",
    "\n",
    "for e in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1]:#10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 1000]:\n",
    "        regr = make_pipeline(StandardScaler(), SVR(C=c, epsilon=e))\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred_test = regr.predict(X_test)\n",
    "        score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "        results.append([e, c, score])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"best score sum method: \", best_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_score = np.infty\n",
    "\n",
    "print(\"\\nStart KNN\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_avg, y, test_size=0.20, random_state=0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([k, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart LR\")\n",
    "results = []\n",
    "\n",
    "for i in range(5):#10):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_test = lr.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([i, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart SVR\")\n",
    "results = []\n",
    "\n",
    "for e in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1]:#10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 1000]:\n",
    "        regr = make_pipeline(StandardScaler(), SVR(C=c, epsilon=e))\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred_test = regr.predict(X_test)\n",
    "        score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "        results.append([e, c, score])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"best score avg method: \", best_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_score = np.infty\n",
    "results = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_150kdim, y, test_size=0.20, random_state=0)\n",
    "\n",
    "for k in [100, 150, 200, 250, 300, 400, 500]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([k, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart LR\")\n",
    "results = []\n",
    "\n",
    "for i in range(5):#10):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_test = lr.predict(X_test)\n",
    "    score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "    results.append([i, score])\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nStart SVR\")\n",
    "results = []\n",
    "\n",
    "for e in [0.000001, 0.00001, 0.01, 0.1, 1]:\n",
    "    for c in [0.001, 1, 10, 20, 100]:\n",
    "        regr = make_pipeline(StandardScaler(), SVR(C=c, epsilon=e))\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred_test = regr.predict(X_test)\n",
    "        score = mean_squared_error(y_pred_test, y_test, squared=False)\n",
    "        results.append([e, c, score])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"best score 150kdim method: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"rand_mdim_sample_100_X\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp.iloc[0].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the first column\n",
    "first_column = [row[0] for row in X_avg]\n",
    "second_column = [row[1] for row in X_avg]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "# Plot scatterplot data (20 2D points per colour) on the x and z axes.\n",
    "colors = ('r', 'g', 'b', 'k')\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "y = pd.read_csv(\"rand_mdim_sample_100_y\", index_col=False)\n",
    "c_list = []\n",
    "for c in colors:\n",
    "    c_list.extend([c] * len(first_column))\n",
    "# By using zdir='y', the y value of these points is fixed to the zs value 0\n",
    "# and the (x, y) points are plotted on the x and z axes.\n",
    "ax.scatter(first_column, y, second_column, zdir='y',label='points in (x, z)', s=3)\n",
    "ax.set_title(\"3d Scatter Plot of Mod. (Avg) Sample Data Set\")\n",
    "# Make legend, set axes limits and labels\n",
    "#ax.legend()\n",
    "ax.set_xlim(-10, 10)\n",
    "ax.set_ylim(-25, 25)\n",
    "ax.set_zlim(0, 14)\n",
    "ax.set_xlabel('Avg of Previous Signals')\n",
    "ax.set_ylabel('Acoustic Signal')\n",
    "ax.set_zlabel('Time to Failure')\n",
    "\n",
    "# Customize the view angle so it's easier to see that the scatter points lie\n",
    "# on the plane y=0\n",
    "ax.view_init(elev=20., azim=-35, roll=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
